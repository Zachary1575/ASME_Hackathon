{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformation for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ImageNet class index to label mapping\n",
    "class_idx = json.loads(requests.get('https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json').text)\n",
    "idx_to_class = {int(k): v[1] for k, v in class_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\richt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def load_images(base_path, n_assemblies=None):\n",
    "    all_images = {}\n",
    "    assembly_folders = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    \n",
    "    # Limit the number of assemblies if specified\n",
    "    if n_assemblies is not None:\n",
    "        assembly_folders = assembly_folders[:n_assemblies]\n",
    "\n",
    "    for assembly_id in assembly_folders:\n",
    "        assembly_path = os.path.join(base_path, assembly_id)\n",
    "        all_images[assembly_id] = {\n",
    "            'assembly': None,\n",
    "            'bodies': {}\n",
    "        }\n",
    "    \n",
    "        for image_name in os.listdir(assembly_path):\n",
    "            if not image_name.endswith('.png'):\n",
    "                continue\n",
    "            image_path = os.path.join(assembly_path, image_name)\n",
    "            with Image.open(image_path) as img:\n",
    "                if image_name == 'assembly.png':\n",
    "                    all_images[assembly_id]['assembly'] = np.array(img)\n",
    "                else:\n",
    "                    body_id = image_name.rstrip('.png')\n",
    "                    all_images[assembly_id]['bodies'][body_id] = np.array(img)\n",
    "\n",
    "    return all_images\n",
    " \"\"\"\n",
    "\n",
    "def load_images(base_path, resize_shape=(256, 256), n_assemblies=None):\n",
    "    all_images = {}\n",
    "    assembly_folders = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    \n",
    "    # Limit the number of assemblies if specified\n",
    "    if n_assemblies is not None:\n",
    "        assembly_folders = assembly_folders[:n_assemblies]\n",
    "\n",
    "    for assembly_id in tqdm(assembly_folders, desc=\"Loading images\"):\n",
    "        assembly_path = os.path.join(base_path, assembly_id)\n",
    "        all_images[assembly_id] = {\n",
    "            'assembly': None,\n",
    "            'bodies': {}\n",
    "        }\n",
    "    \n",
    "        for image_name in os.listdir(assembly_path):\n",
    "            if not image_name.endswith('.png'):\n",
    "                continue\n",
    "            image_path = os.path.join(assembly_path, image_name)\n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.resize(resize_shape)\n",
    "                if image_name == 'assembly.png':\n",
    "                    all_images[assembly_id]['assembly'] = np.array(img)\n",
    "                else:\n",
    "                    body_id = image_name.rstrip('.png')\n",
    "                    all_images[assembly_id]['bodies'][body_id] = np.array(img)\n",
    "\n",
    "    return all_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image, model, transform, topk=5):\n",
    "    # If image is a path, then load it; otherwise, assume it's already an array\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image)\n",
    "    else:\n",
    "        image = Image.fromarray(image)\n",
    "    \n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    image = image.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probs, indices = output.topk(topk)\n",
    "        probs = F.softmax(probs, dim=1)[0] * 100\n",
    "        indices = indices[0]\n",
    "    \n",
    "    labels = [idx_to_class[int(idx.item())] for idx in indices]\n",
    "    return labels, probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_images(all_images, model, transform):\n",
    "    predictions = {}\n",
    "    \n",
    "    for assembly_id, images in all_images.items():\n",
    "        predictions[assembly_id] = {\n",
    "            'assembly': None,\n",
    "            'bodies': {}\n",
    "        }\n",
    "        \n",
    "        # Predict for assembly image\n",
    "        labels, probabilities = predict_image(images['assembly'], model, transform)\n",
    "        predictions[assembly_id]['assembly'] = (labels, probabilities)\n",
    "        \n",
    "        # Predict for body images\n",
    "        for body_id, body_image in images['bodies'].items():\n",
    "            labels, probabilities = predict_image(body_image, model, transform)\n",
    "            predictions[assembly_id]['bodies'][body_id] = (labels, probabilities)\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_dataframe(all_predictions, topk=5):\n",
    "    # Lists to store data for assemblies and bodies\n",
    "    assembly_data = []\n",
    "    body_data = []\n",
    "\n",
    "    for assembly_id, predictions in all_predictions.items():\n",
    "        # Process assembly predictions\n",
    "        assembly_labels, assembly_probs = predictions['assembly']\n",
    "        assembly_dict = {\n",
    "            'assembly_id': assembly_id,\n",
    "        }\n",
    "        for i in range(topk):\n",
    "            assembly_dict[f'assembly_prediction_{i + 1}'] = assembly_labels[i]\n",
    "            assembly_dict[f'assembly_probability_{i + 1}'] = assembly_probs[i]\n",
    "        assembly_data.append(assembly_dict)\n",
    "\n",
    "        # Process body predictions\n",
    "        for body_id, (body_labels, body_probs) in predictions['bodies'].items():\n",
    "            body_dict = {\n",
    "                'assembly_id': assembly_id,\n",
    "                'body_id': body_id\n",
    "            }\n",
    "            for i in range(topk):\n",
    "                body_dict[f'prediction_{i + 1}'] = body_labels[i]\n",
    "                body_dict[f'probability_{i + 1}'] = body_probs[i]\n",
    "            body_data.append(body_dict)\n",
    "\n",
    "    # Convert lists to dataframes\n",
    "    df_assembly_predictions = pd.DataFrame(assembly_data)\n",
    "    df_body_predictions = pd.DataFrame(body_data)\n",
    "    \n",
    "    return df_assembly_predictions, df_body_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Load images\\nbase_path = \"C:\\\\Users\\\\richt\\\\Documents\\\\ASME_data\\\\train\\\\Fusion360GalleryDataset_23hackathon_train\"\\nall_images = load_images(base_path, resize_shape=(128, 128)) '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Load images\n",
    "base_path = \"C:\\\\Users\\\\richt\\\\Documents\\\\ASME_data\\\\train\\\\Fusion360GalleryDataset_23hackathon_train\"\n",
    "all_images = load_images(base_path, resize_shape=(128, 128)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "base_path_test = \"C:\\\\Users\\\\richt\\\\Documents\\\\ASME_data\\\\test\\\\Fusion360GalleryDataset_23hackathon_test\"\n",
    "all_images_test = load_images(base_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # To save the all_images dictionary to a file:\\nwith open(\"all_images.pkl\", \"wb\") as f:\\n    pickle.dump(all_images, f) '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # To save the all_images dictionary to a file:\n",
    "with open(\"all_images.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_images, f) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the all_images dictionary to a file:\n",
    "with open(\"all_images_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_images_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import matplotlib.pyplot as plt\\n\\ndef visualize_assemblies_and_bodies(images_dict):\\n    # Selecting the first 3 assemblies\\n    assemblies = list(images_dict.keys())[:3]\\n    \\n    fig, axes = plt.subplots(3, 5, figsize=(20, 15))  # 3 assemblies, up to 5 images each (assembly + up to 4 bodies)\\n    \\n    for i, assembly in enumerate(assemblies):\\n        # Displaying assembly image\\n        axes[i, 0].imshow(images_dict[assembly][\\'assembly\\'], cmap=\\'gray\\')\\n        axes[i, 0].set_title(f\"{assembly} - Assembly\")\\n        axes[i, 0].axis(\\'off\\')\\n\\n        # Displaying up to the first 4 body images if they exist\\n        body_ids = list(images_dict[assembly][\\'bodies\\'].keys())\\n        for j in range(4):\\n            if j < len(body_ids):  # if there\\'s a body to display\\n                axes[i, j+1].imshow(images_dict[assembly][\\'bodies\\'][body_ids[j]], cmap=\\'gray\\')\\n                axes[i, j+1].set_title(f\"{assembly} - Body {body_ids[j]}\")\\n                axes[i, j+1].axis(\\'off\\')\\n            else:\\n                axes[i, j+1].axis(\\'off\\')  # Turn off axis if no more bodies to display\\n\\n    plt.tight_layout()\\n    plt.show()\\n\\n# Now, let\\'s call this function to visualize the images\\nvisualize_assemblies_and_bodies(all_images)\\n '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_assemblies_and_bodies(images_dict):\n",
    "    # Selecting the first 3 assemblies\n",
    "    assemblies = list(images_dict.keys())[:3]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 5, figsize=(20, 15))  # 3 assemblies, up to 5 images each (assembly + up to 4 bodies)\n",
    "    \n",
    "    for i, assembly in enumerate(assemblies):\n",
    "        # Displaying assembly image\n",
    "        axes[i, 0].imshow(images_dict[assembly]['assembly'], cmap='gray')\n",
    "        axes[i, 0].set_title(f\"{assembly} - Assembly\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Displaying up to the first 4 body images if they exist\n",
    "        body_ids = list(images_dict[assembly]['bodies'].keys())\n",
    "        for j in range(4):\n",
    "            if j < len(body_ids):  # if there's a body to display\n",
    "                axes[i, j+1].imshow(images_dict[assembly]['bodies'][body_ids[j]], cmap='gray')\n",
    "                axes[i, j+1].set_title(f\"{assembly} - Body {body_ids[j]}\")\n",
    "                axes[i, j+1].axis('off')\n",
    "            else:\n",
    "                axes[i, j+1].axis('off')  # Turn off axis if no more bodies to display\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Now, let's call this function to visualize the images\n",
    "visualize_assemblies_and_bodies(all_images)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Make predictions\\nall_predictions = predict_for_images(all_images, model, transform)\\n\\n# [Further code for storing predictions and merging with df_main if needed] '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Make predictions\n",
    "all_predictions = predict_for_images(all_images, model, transform)\n",
    "\n",
    "# [Further code for storing predictions and merging with df_main if needed] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_predictions = predict_for_images(all_images_test, model, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Convert predictions to dataframes\\ndf_assembly_predictions, df_body_predictions = predictions_to_dataframe(all_predictions) '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Convert predictions to dataframes\n",
    "df_assembly_predictions, df_body_predictions = predictions_to_dataframe(all_predictions) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to dataframes\n",
    "df_assembly_predictions_test, df_body_predictions_test = predictions_to_dataframe(all_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      assembly_id assembly_prediction_1  assembly_probability_1  \\\n",
       " 5  35584_fb213b6b               padlock               46.227245   \n",
       " 6  43630_515b0cd2         rocking_chair               41.330933   \n",
       " 7  55199_4d57661f                 loupe               35.880558   \n",
       " 8  72966_11b78e5e      pencil_sharpener               52.291607   \n",
       " 9  74576_73ac0093          dining_table               94.939171   \n",
       " \n",
       "   assembly_prediction_2  assembly_probability_2 assembly_prediction_3  \\\n",
       " 5      combination_lock               43.865902               lighter   \n",
       " 6          barber_chair               18.414169              bassinet   \n",
       " 7               barbell               33.910595      magnetic_compass   \n",
       " 8           face_powder               21.584303              dumbbell   \n",
       " 9         folding_chair                2.509799                  desk   \n",
       " \n",
       "    assembly_probability_3 assembly_prediction_4  assembly_probability_4  \\\n",
       " 5                5.058557                 loupe                3.763767   \n",
       " 6               15.720625         folding_chair               14.815050   \n",
       " 7               10.727509                 scale               10.576344   \n",
       " 8               13.469453                  puck                6.508044   \n",
       " 9                1.274445        potter's_wheel                0.681813   \n",
       " \n",
       "   assembly_prediction_5  assembly_probability_5  \n",
       " 5              cassette                1.084528  \n",
       " 6                  desk                9.719228  \n",
       " 7            microphone                8.904994  \n",
       " 8          analog_clock                6.146588  \n",
       " 9           mortarboard                0.594775  ,\n",
       "         assembly_id                               body_id  prediction_1  \\\n",
       " 150  74576_73ac0093  3b4ce74c-05cc-11ec-a9ce-064a63348d37  sliding_door   \n",
       " 151  74576_73ac0093  3b4d0e4c-05cc-11ec-9c6d-064a63348d37  sliding_door   \n",
       " 152  74576_73ac0093  3b4d355a-05cc-11ec-9f42-064a63348d37  sliding_door   \n",
       " 153  74576_73ac0093  3b4d8388-05cc-11ec-acde-064a63348d37  sliding_door   \n",
       " 154  74576_73ac0093  3b4daaa2-05cc-11ec-bc9f-064a63348d37     hard_disc   \n",
       " \n",
       "      probability_1 prediction_2  probability_2 prediction_3  probability_3  \\\n",
       " 150      30.820665         pole      24.868977   table_lamp      17.045713   \n",
       " 151      30.820665         pole      24.868977   table_lamp      17.045713   \n",
       " 152      30.820665         pole      24.868977   table_lamp      17.045713   \n",
       " 153      30.820665         pole      24.868977   table_lamp      17.045713   \n",
       " 154      30.940014     envelope      21.721716        scale      19.142384   \n",
       " \n",
       "     prediction_4  probability_4 prediction_5  probability_5  \n",
       " 150   guillotine      15.840091      monitor      11.424552  \n",
       " 151   guillotine      15.840091      monitor      11.424552  \n",
       " 152   guillotine      15.840091      monitor      11.424552  \n",
       " 153   guillotine      15.840091      monitor      11.424552  \n",
       " 154  mortarboard      17.675535       binder      10.520356  )"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assembly_predictions_test.tail(5), df_body_predictions_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Loading the df_main.pickle file\\ndf_main = pd.read_pickle(\"df_main.pkl\")\\ndf_main.shape '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Loading the df_main.pickle file\n",
    "df_main = pd.read_pickle(\"df_main.pkl\")\n",
    "df_main.shape \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 38)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the df_main.pickle file\n",
    "df_main_test = pd.read_pickle(\"df_test_main_fe.pkl\")\n",
    "df_main_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Start with df_main\\nmerged_df = df_main.copy()\\n\\n# Merge with assembly predictions\\nmerged_df = merged_df.merge(df_assembly_predictions, on='assembly_id', how='left')\\n\\n# Merge with body predictions\\nmerged_df = merged_df.merge(df_body_predictions, on=['assembly_id', 'body_id'], how='left', suffixes=('', '_body'))\\n\\n# Handle any NaN values that might arise due to missing predictions\\nfor col in merged_df.columns:\\n    if 'prediction' in col or 'probability' in col:\\n        merged_df[col].fillna('', inplace=True) \""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Start with df_main\n",
    "merged_df = df_main.copy()\n",
    "\n",
    "# Merge with assembly predictions\n",
    "merged_df = merged_df.merge(df_assembly_predictions, on='assembly_id', how='left')\n",
    "\n",
    "# Merge with body predictions\n",
    "merged_df = merged_df.merge(df_body_predictions, on=['assembly_id', 'body_id'], how='left', suffixes=('', '_body'))\n",
    "\n",
    "# Handle any NaN values that might arise due to missing predictions\n",
    "for col in merged_df.columns:\n",
    "    if 'prediction' in col or 'probability' in col:\n",
    "        merged_df[col].fillna('', inplace=True) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with df_main\n",
    "merged_df_test = df_main_test.copy()\n",
    "\n",
    "# Merge with assembly predictions\n",
    "merged_df_test = merged_df_test.merge(df_assembly_predictions_test, on='assembly_id', how='left')\n",
    "\n",
    "# Merge with body predictions\n",
    "merged_df_test = merged_df_test.merge(df_body_predictions_test, on=['assembly_id', 'body_id'], how='left', suffixes=('', '_body'))\n",
    "\n",
    "# Handle any NaN values that might arise due to missing predictions\n",
    "for col in merged_df_test.columns:\n",
    "    if 'prediction' in col or 'probability' in col:\n",
    "        merged_df_test[col].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" pd.set_option('display.max_columns', None)\\nmerged_df.tail(10) \""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" pd.set_option('display.max_columns', None)\n",
    "merged_df.tail(10) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 58)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "merged_df_test.tail(10)#\n",
    "merged_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' merged_df.to_pickle(\"df_main_images.pkl\") '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" merged_df.to_pickle(\"df_main_images.pkl\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_test.to_pickle(\"df_main_images_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
