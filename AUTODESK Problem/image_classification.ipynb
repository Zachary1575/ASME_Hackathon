{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df_main = pd.read_pickle('df_main.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ImageNet class index to label mapping\n",
    "IMAGENET_CLASSES_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\"\n",
    "response = requests.get(IMAGENET_CLASSES_URL)\n",
    "class_idx = response.json()\n",
    "\n",
    "# Convert it to the idx_to_class dictionary\n",
    "idx_to_class = {int(k): v[1] for k, v in class_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image, model, transform, topk=5):\n",
    "    \"\"\"\n",
    "    Predict the top-k categories for an image.\n",
    "    \"\"\"\n",
    "    # If image is a path, then load it; otherwise, assume it's already an array\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image)\n",
    "    else:\n",
    "        image = Image.fromarray(image)\n",
    "    \n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    image = image.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probs, indices = output.topk(topk)\n",
    "        probs = F.softmax(probs, dim=1)[0] * 100\n",
    "        indices = indices[0]\n",
    "    \n",
    "    labels = [idx_to_class[int(idx.item())] for idx in indices]\n",
    "    #labels = [idx_to_class[idx] for idx in indices]\n",
    "    return labels, probs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_directory(base_path, limit=None):\n",
    "    all_images = {}\n",
    "    assembly_folders = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    \n",
    "    if limit:\n",
    "        assembly_folders = assembly_folders[:limit]\n",
    "    \n",
    "    for assembly_id in tqdm(assembly_folders, desc=\"Loading images\"):\n",
    "        assembly_path = os.path.join(base_path, assembly_id)\n",
    "        all_images[assembly_id] = {\n",
    "            'assembly': None,\n",
    "            'bodies': {}\n",
    "        }\n",
    "        \n",
    "        for image_name in os.listdir(assembly_path):\n",
    "            if not image_name.endswith('.png'):  # Only process .png files\n",
    "                continue\n",
    "                \n",
    "            image_path = os.path.join(assembly_path, image_name)\n",
    "            body_id = image_name.rstrip('.png')  # Use the filename as body_id\n",
    "            \n",
    "            # Load assembly image\n",
    "            if image_name == 'assembly.png':\n",
    "                with Image.open(image_path) as img:\n",
    "                    all_images[assembly_id]['assembly'] = np.array(img)\n",
    "                    \n",
    "            # Load body images\n",
    "            else:\n",
    "                with Image.open(image_path) as img:\n",
    "                    all_images[assembly_id]['bodies'][body_id] = np.array(img)\n",
    "                    \n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_first_n_images(all_images, model, transform, n=3):\n",
    "    predictions = {}\n",
    "    for assembly_id, images in list(all_images.items())[:n]:\n",
    "        predictions[assembly_id] = {\n",
    "            'assembly': None,\n",
    "            'bodies': {}\n",
    "        }\n",
    "        \n",
    "        # Predict for the assembly image\n",
    "        assembly_image = images['assembly']\n",
    "        if assembly_image is not None:\n",
    "            labels, probabilities = predict_image(assembly_image, model, transform)\n",
    "            predictions[assembly_id]['assembly'] = (labels, probabilities)\n",
    "            \n",
    "        # Predict for the body images\n",
    "        for body_id, body_image in images['bodies'].items():\n",
    "            labels, probabilities = predict_image(body_image, model, transform)\n",
    "            predictions[assembly_id]['bodies'][body_id] = (labels, probabilities)\n",
    "            print(f\"Stored predictions for body {body_id} of assembly {assembly_id}.\")\n",
    "            \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_predictions(all_images, predictions, top_n=20):\n",
    "    # Flatten the predictions and their associated image IDs and types\n",
    "    flattened_predictions = []\n",
    "    for image_id, prediction_data in predictions.items():\n",
    "        for image_type, prediction in prediction_data.items():\n",
    "            # Handle assembly predictions\n",
    "            if image_type == 'assembly' and isinstance(prediction, tuple) and len(prediction) == 2:\n",
    "                labels, probabilities = prediction\n",
    "                for label, prob in zip(labels, probabilities):\n",
    "                    flattened_predictions.append({\n",
    "                        'image_id': image_id,\n",
    "                        'image_type': image_type,\n",
    "                        'label': label,\n",
    "                        'probability': prob,\n",
    "                        'image': all_images[image_id][image_type]\n",
    "                    })\n",
    "            # Handle body predictions\n",
    "            elif image_type == 'bodies':\n",
    "                for idx, body_prediction in enumerate(prediction):\n",
    "                    if isinstance(body_prediction, tuple) and len(body_prediction) == 2:\n",
    "                        labels, probabilities = body_prediction\n",
    "                        for label, prob in zip(labels, probabilities):\n",
    "                            flattened_predictions.append({\n",
    "                                'image_id': image_id,\n",
    "                                'image_type': f\"{image_type}_{idx}\",\n",
    "                                'label': label,\n",
    "                                'probability': prob,\n",
    "                                'image': all_images[image_id][image_type][idx]\n",
    "                            })\n",
    "    \n",
    "    # Sort the predictions by probability in descending order and take top_n\n",
    "    top_predictions = sorted(flattened_predictions, key=lambda x: x['probability'], reverse=True)[:top_n]\n",
    "    \n",
    "    # Plot the top predictions\n",
    "    fig, axs = plt.subplots(int(top_n/4), 4, figsize=(15, 5*int(top_n/4)))\n",
    "    for ax, pred in zip(axs.ravel(), top_predictions):\n",
    "        ax.imshow(pred['image'])\n",
    "        ax.set_title(f\"{pred['label']} ({pred['probability']:.2f}%)\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:\\\\Users\\\\richt\\\\Documents\\\\ASME_data\\\\train\\\\Fusion360GalleryDataset_23hackathon_train\"\n",
    "all_images = load_images_from_directory(base_path, limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.eval() # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set device accordingly\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_indices = set(range(1000)) - set(idx_to_class.keys())\n",
    "print(f\"Missing indices: {missing_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_sel = len(all_images)\n",
    "n_sel = 20\n",
    "selected_predictions = predict_first_n_images(all_images, model, transform, n=n_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id, prediction_data in selected_predictions.items():\n",
    "    print(f\"\\nPredictions for Image ID: {image_id}\")\n",
    "    \n",
    "    for image_type, predictions in prediction_data.items():\n",
    "        print(\"\\nProcessing image type:\", image_type)  # Added Diagnostic print statement\n",
    "\n",
    "        print(f\"\\n  {image_type} Predictions:\")\n",
    "        \n",
    "        if image_type == 'assembly':\n",
    "\n",
    "            if isinstance(predictions, tuple) and len(predictions) == 2:\n",
    "                labels, probabilities = predictions\n",
    "                for label, prob in zip(labels, probabilities):\n",
    "                    print(f\"    Label: {label}, Probability: {prob:.2f}%\")\n",
    "            else:\n",
    "                print(\"    No predictions available for this image type.\")\n",
    "\n",
    "        elif image_type == 'bodies':\n",
    "            print(\"Inside 'bodies' condition\")  # Added Diagnostic print statement\n",
    "\n",
    "            for body_id, body_prediction in predictions.items():\n",
    "                print(f\"Processing body ID: {body_id}\")  # Added Diagnostic print statement\n",
    "\n",
    "                if isinstance(body_prediction, tuple) and len(body_prediction) == 2:\n",
    "                    labels, _ = body_prediction\n",
    "                    body_data.append({'body_id': body_id, 'body_label': ', '.join(labels)})\n",
    "                    print(f\"Added body_id {body_id} with labels: {', '.join(labels)}\")\n",
    "                else:\n",
    "                    print(f\"No tuple predictions for body ID: {body_id}\")  # Added Diagnostic print statement\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(body_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the plotting function\n",
    "plot_top_predictions(all_images, selected_predictions, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for assembly_id, images in all_images.items():\n",
    "    if images['bodies']:\n",
    "        print(f\"Assembly {assembly_id} has {len(images['bodies'])} body images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes to store the results for assemblies and bodies\n",
    "assembly_data = []\n",
    "body_data = []\n",
    "\n",
    "for image_id, prediction_data in selected_predictions.items():\n",
    "    for image_type, prediction in prediction_data.items():\n",
    "        if image_type == 'assembly' and isinstance(prediction, tuple) and len(prediction) == 2:\n",
    "            labels, _ = prediction\n",
    "            assembly_data.append({'assembly_id': image_id, 'assembly_label': ', '.join(labels)})\n",
    "        elif image_type == 'bodies':\n",
    "            for body_idx, body_prediction in enumerate(prediction):\n",
    "                if isinstance(body_prediction, tuple) and len(body_prediction) == 2:\n",
    "                    labels, _ = body_prediction\n",
    "                    body_id = f\"{image_id}_body_{body_idx}\"  # Constructing body_id from image_id and body_idx\n",
    "                    body_data.append({'body_id': body_id, 'body_label': ', '.join(labels)})\n",
    "                    print(f\"Added body_id {body_id} with labels: {', '.join(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of dictionaries to dataframes\n",
    "df_assembly_predictions = pd.DataFrame(assembly_data)\n",
    "df_body_predictions = pd.DataFrame(body_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_body_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicting for body {body_id} of assembly {assembly_id}...\")\n",
    "labels, probabilities = predict_image(body_image, model, transform)\n",
    "print(f\"Predictions: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if assembly_id not in predictions:\n",
    "    predictions[assembly_id] = {}\n",
    "if 'bodies' not in predictions[assembly_id]:\n",
    "    predictions[assembly_id]['bodies'] = {}\n",
    "predictions[assembly_id]['bodies'][body_id] = (labels, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_main\n",
    "df_main = df_main.merge(df_assembly_predictions, on='assembly_id', how='left')\n",
    "df_main = df_main.merge(df_body_predictions, on='body_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the body images\n",
    "for body_id, body_image in images['bodies'].items():\n",
    "    labels, probabilities = predict_image(body_image, model, transform)\n",
    "    predictions[assembly_id]['bodies'][body_id] = (labels, probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicting for body {body_id} of assembly {assembly_id}...\")\n",
    "labels, probabilities = predict_image(body_image, model, transform)\n",
    "print(f\"Predictions: {labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_id = f\"{image_id}_body_{body_idx}\"  # Constructing body_id from image_id and body_idx\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
