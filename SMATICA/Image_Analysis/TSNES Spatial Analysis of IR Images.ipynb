{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29de5835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 16:05:37.297633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29373d6f",
   "metadata": {},
   "source": [
    "# Data Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../FLIR_Data/\"\n",
    "\n",
    "# Assumes that all images are of the same shape...\n",
    "def readRawData(source_base_path, verbose = False):\n",
    "    \"\"\"\n",
    "    Reads raw image data O(n)\n",
    "    \n",
    "    Parameters\n",
    "    -----------------\n",
    "    source_base_path: String path of the root folder for the dataset \n",
    "    \n",
    "    Returns\n",
    "    -----------------\n",
    "    X_data: returns an Array of Heterogenous (RGB) values of input data for the tensor network\n",
    "    \"\"\"\n",
    "\n",
    "    image_name_arr = glob.glob(os.path.join(source_base_path, \"*.png\")) + glob.glob(os.path.join(source_base_path, \"*.jpg\"));\n",
    "    image_name_arr_sorted = sorted(image_name_arr, key = lambda x:x[0:]);\n",
    "    \n",
    "    original = [];\n",
    "    \n",
    "    for infile in image_name_arr_sorted:\n",
    "        original_img = cv2.imread(infile);\n",
    "        original.append(original_img);\n",
    "        \n",
    "        if (verbose): # If set to true, the runtime is slower...\n",
    "            plt.imshow(original_img);\n",
    "            plt.show()\n",
    "    \n",
    "    return np.array(original);\n",
    "\n",
    "X_data = read_data(root_path);\n",
    "\n",
    "# Sanity Check\n",
    "print(\"X_Training data shape:\", X_data.shape);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb004c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUTURE USE (Once we get morphological data...)\n",
    "\n",
    "# def read_data(source_base_path, img_folder_name, seg_folder_name, verbose = False):\n",
    "#     \"\"\"\n",
    "#     Reads the data and splits it from X_data and Labels O(n)\n",
    "    \n",
    "#     Parameters\n",
    "#     -----------------\n",
    "#     source_base_path: String path of the root folder for the dataset \n",
    "#     (Assumes that there is a seg_folder and img_folder.)\n",
    "#     img_folder_name: String of the image folder name found within the source_base_path\n",
    "#     seg_folder_name: String of the segmentation folder name found within the source_base_path\n",
    "    \n",
    "#     Returns\n",
    "#     -----------------\n",
    "#     X_data: returns an Array of Heterogenous (RGB) values of input data for the tensor network\n",
    "#     Y_Data: returns an Array of Heterogenous (RGB) value of segmentation masks for the tensor network\n",
    "#     max_dim: greatest height and width, respectively, in given images\n",
    "#     \"\"\"\n",
    "    \n",
    "#     img_base_path = source_base_path + \"/\" + img_folder_name + \"/\";\n",
    "    \n",
    "#     image_name_arr = glob.glob(os.path.join(img_base_path, \"*.png\")) + glob.glob(os.path.join(img_base_path, \"*.tif\"));\n",
    "#     image_name_arr_sorted = sorted(image_name_arr, key = lambda x:x[0:]);\n",
    "    \n",
    "#     original = [];\n",
    "#     masks = [];\n",
    "\n",
    "#     max_height = 0\n",
    "#     max_width = 0   \n",
    "    \n",
    "#     for infile in image_name_arr_sorted:\n",
    "#         seg_path = infile.replace(img_folder_name, seg_folder_name); \n",
    "        \n",
    "#         original_img = cv2.imread(infile);\n",
    "#         seg_img = cv2.imread(seg_path);\n",
    "        \n",
    "#         height, width, _  = np.shape(original_img)\n",
    "#         # Check if the height and width is greater than greatest\n",
    "#         if height > max_height:\n",
    "#             max_height = height\n",
    "\n",
    "#         if width > max_width:\n",
    "#             max_width = width\n",
    "\n",
    "#         original.append(original_img);\n",
    "#         masks.append(seg_img);\n",
    "        \n",
    "#         if (verbose): # If set to true, the runtime is slower...\n",
    "#             plt.imshow(original_img);\n",
    "#             plt.show()\n",
    "#             plt.imshow(seg_img);\n",
    "#             plt.show()\n",
    "    \n",
    "#     return original, masks, (max_height, max_width);\n",
    "\n",
    "# X_data, Y_data, max_dim = read_data(root_path, \"img\", \"seg\");\n",
    "\n",
    "# # Sanity Check\n",
    "# print(\"X_Training data length:\", len(X_data))\n",
    "# print(\"Y_Training data length:\", len(Y_data))\n",
    "# print(\"Max_Dimensions:\", max_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c0123",
   "metadata": {},
   "source": [
    "# Feature Vector Embedding: Extraction of Features using ResNet 50-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_101 = ResNetEncoder101()\n",
    "model_50 = ResNetEncoder50()\n",
    "features_vectors_101 = model_101.predict(Overall_Images, batch_size = 32)\n",
    "features_vectors_50 = model_50.predict(Overall_Images, batch_size = 32)\n",
    "\n",
    "print(features_vectors_101)\n",
    "print(features_vectors_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa53518",
   "metadata": {},
   "source": [
    "## t-SNE Conversion and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and move the coordinates so they fit [0; 1] range\n",
    "def scale_to_01_range(x):\n",
    "    value_range = (np.max(x) - np.min(x))\n",
    "    starts_from_zero = x - np.min(x)\n",
    "    return starts_from_zero / value_range\n",
    "\n",
    "# ======================================================\n",
    "\n",
    "# We want to get TSNE embedding with 2 dimensions\n",
    "n_components = 2\n",
    "tsne_101 = TSNE(n_components)\n",
    "tsne_X_101 = tsne_101.fit_transform(features_vectors_101)\n",
    "tsne_X_101.shape\n",
    "\n",
    "tx_101 = tsne_X_101[:, 0]\n",
    "ty_101 = tsne_X_101[:, 1]\n",
    " \n",
    "tx_101 = scale_to_01_range(tx_101)\n",
    "ty_101 = scale_to_01_range(ty_101)\n",
    "\n",
    "# ======================================================\n",
    "\n",
    "# We want to get TSNE embedding with 2 dimensions\n",
    "n_components = 2\n",
    "tsne_50 = TSNE(n_components)\n",
    "tsne_X_50 = tsne_50.fit_transform(features_vectors_50)\n",
    "tsne_X_50.shape\n",
    "\n",
    "tx_50 = tsne_X_50[:, 0]\n",
    "ty_50 = tsne_X_50[:, 1]\n",
    " \n",
    "tx_50 = scale_to_01_range(tx_50)\n",
    "ty_50 = scale_to_01_range(ty_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x = tx_101, y = ty_101, color=Overall_Labels.flatten())\n",
    "fig.update_layout(\n",
    "    title=\"t-SNE visualization of Custom Dataset with RESNET-101\",\n",
    "    xaxis_title=\"First t-SNE\",\n",
    "    yaxis_title=\"Second t-SNE\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(x = tx_50, y = ty_50, color=Overall_Labels.flatten())\n",
    "fig.update_layout(\n",
    "    title=\"t-SNE visualization of Custom Dataset with RESNET-50\",\n",
    "    xaxis_title=\"First t-SNE\",\n",
    "    yaxis_title=\"Second t-SNE\",\n",
    ")\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7544968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ba58d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647cb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50699c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5043fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
